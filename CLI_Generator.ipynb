{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "Qo5OoQpSOdQa"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMT85vLvB6gw7Zt6qB7OTX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generates gCloud CLI Commands Based On User's Input\n",
        "You can see a UI version of this [here](https://cligenerator.xyz/).\n",
        "Supporting Github repo is [here](https://github.com/UriKatsirPrivate/CLI-Generator)."
      ],
      "metadata": {
        "id": "NTlBIE1YLoBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "1.   GCP Project\n",
        "2.   [Enable](https://cloud.google.com/apis/docs/getting-started#enabling_apis) Vertex AI API\n",
        "3.   IAM User with *Vertex AI User* permissions\n",
        "  *   Uae this IAM user to login to this colab and to authenticate to Google Cloud in the step below"
      ],
      "metadata": {
        "id": "Qo5OoQpSOdQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "JHfYeGdlOg5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "R5ng-AJlOznw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install google-cloud-aiplatform==1.36.2\n",
        "!pip -q install langchain==0.0.329"
      ],
      "metadata": {
        "id": "hNMZJkLizTJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚠️ Restart the session:\n",
        "\n",
        "Runtime--> Restart runtime or run the 2 rows below"
      ],
      "metadata": {
        "id": "nFj2sCoLO6iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "r6Lic2fAICr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔐 Authenticate to Google Cloud\n",
        "\n",
        "Use the same user you configured during the Prerequisites step above."
      ],
      "metadata": {
        "id": "JNxho3EdPMhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "PWqdnbF_2-lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Blocks"
      ],
      "metadata": {
        "id": "UpDtalmRPWyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Variables"
      ],
      "metadata": {
        "id": "A5t04DePPndW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title { run: \"auto\" }\n",
        "project_id = \"*** REQUIRED ***\" # @param {type:\"string\"}\n",
        "region = \"us-central1\" # @param {type:\"string\"}\n",
        "model_name = \"text-bison-32k\" # @param [\"text-bison\", \"text-bison-32k\", \"code-bison\", \"code-bison-32k\"]\n",
        "max_tokens = 8192 # @param {type:\"slider\", min:1, max:8192, step:1}\n",
        "temperature = \"0.1\" # @param {type:\"string\"}\n",
        "top_p = \"0.8\" # @param {type:\"string\"}\n",
        "top_k = \"40\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "if not ('32k' in model_name) and max_tokens>1024:\n",
        "  raise RuntimeError(f'{max_tokens} output tokens is not a valid value for model {model_name}')\n"
      ],
      "metadata": {
        "id": "VZDhR-RoCE8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable APIs"
      ],
      "metadata": {
        "id": "WkgbRb3lPuid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable aiplatform.googleapis.com --project {project_id} --async"
      ],
      "metadata": {
        "id": "AGrL5f1bPyeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "nrfKlwVIP7_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts.chat import (ChatPromptTemplate,\n",
        "                                    HumanMessagePromptTemplate,\n",
        "                                    SystemMessagePromptTemplate)\n",
        "from langchain.llms import VertexAI"
      ],
      "metadata": {
        "id": "MYVfAMx13Nqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_llm(project_id,region,model_name,max_output_tokens,temperature,top_p,top_k):\n",
        "\n",
        "    # Initialize VertexAI and set up the LLM\n",
        "    return VertexAI(\n",
        "        project=project_id,\n",
        "        location=region,\n",
        "        model_name=model_name,\n",
        "        max_output_tokens=max_output_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        verbose=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "usXlnng3Dh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gcpCliCommandGenerator(user_input):\n",
        "\n",
        "    llm = initialize_llm(project_id,region,model_name,max_tokens,temperature,top_p,top_k)\n",
        "\n",
        "    system_template = \"\"\"You are a virtual assistant capable of generating the corresponding Google Cloud Platform (GCP) command-line interface (CLI) command based on the user's input.\"\"\"\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "    human_template = \"\"\"The user's input is: '{user_input}'. Please generate the corresponding GCP CLI command.\"\"\"\n",
        "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "    chat_prompt = ChatPromptTemplate.from_messages(\n",
        "        [system_message_prompt, human_message_prompt]\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
        "    result = chain.run(user_input=user_input)\n",
        "    return result # returns string"
      ],
      "metadata": {
        "cellView": "code",
        "id": "7M9Z553D9T7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute the Service"
      ],
      "metadata": {
        "id": "JhhqBW9-QE-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"create vpc\" # @param {type:\"string\"}\n",
        "gcp_command = gcpCliCommandGenerator(user_input)"
      ],
      "metadata": {
        "id": "bT4GBj_w92Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gcp_command)"
      ],
      "metadata": {
        "id": "HdmjMxLS-NfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}